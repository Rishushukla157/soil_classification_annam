{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch.optim as optim\nfrom sklearn.metrics import f1_score\n\n# Define paths\ntrain_dir = '/kaggle/input/soil-classification-part-2/soil_competition-2025/train'\ntrain_labels_path = '/kaggle/input/soil-classification-part-2/soil_competition-2025/train_labels.csv'\n\n# Load labels\ndf = pd.read_csv(train_labels_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Data Transforms and Dataset Class\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define transforms for training and validation\nimage_size = 224\ntrain_transform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Custom Dataset Class\nclass SoilDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.df = dataframe.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = self.df.loc[idx, 'image_id']\n        label = self.df.loc[idx, 'label']\n        img_path = os.path.join(self.img_dir, img_name)\n        image = Image.open(img_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Data Loading and Splitting","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the data\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n\n# Create datasets\ntrain_dataset = SoilDataset(train_df, train_dir, transform=train_transform)\nval_dataset = SoilDataset(val_df, train_dir, transform=val_transform)\n\n# Create data loaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Model Architecture Setup","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load pretrained EfficientNet\nmodel = models.efficientnet_b0(pretrained=True)\n\n# Replace classifier for binary classification\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n\nmodel = model.to(device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Training Loop Implementation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\ndef evaluate(model, dataloader):\n    model.eval()\n    y_true, y_pred = [], []\n    \n    with torch.no_grad():\n        for images, labels in dataloader:\n            images = images.to(device)\n            labels = labels.to(device).float().unsqueeze(1)\n\n            outputs = model(images)\n            preds = torch.sigmoid(outputs) > 0.5\n\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n\n    f1 = f1_score(y_true, y_pred)\n    return f1\n\n# Training loop\nepochs = 5\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device).float().unsqueeze(1)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    val_f1 = evaluate(model, val_loader)\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Val F1: {val_f1:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}