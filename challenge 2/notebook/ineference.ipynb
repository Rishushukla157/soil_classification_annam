{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" Import Required Libraries","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\nfrom torch.utils.data import Dataset, DataLoader\n\n# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Define Model Architecture (Same as Training)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_soil_model():\n    \"\"\"Create the same EfficientNet-B0 model as used in training\"\"\"\n    model = models.efficientnet_b0(pretrained=False)  # No need for pretrained weights\n    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n    return model\n\n# Create model instance\nmodel = create_soil_model()\nmodel = model.to(device)\nmodel.eval()\nprint(\"✅ Model architecture created\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" Define Image Preprocessing (Same as Training)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image preprocessing (exactly same as your training)\nimage_size = 224\nval_transform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\nprint(\"✅ Image transforms defined\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Load Trained Model Weights (Optional)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_trained_model(model, model_path=None):\n    \"\"\"Load your trained model weights\"\"\"\n    if model_path and os.path.exists(model_path):\n        model.load_state_dict(torch.load(model_path, map_location=device))\n        print(f\"✅ Model loaded from {model_path}\")\n    else:\n        print(\"⚠️ No model path provided. Using current model weights.\")\n    \n    model.eval()\n    return model\n\n# Load model (update path if you have saved weights)\nmodel = load_trained_model(model, model_path=None)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Define Test Dataset Class","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TestDataset(Dataset):\n    \"\"\"Test dataset class for inference\"\"\"\n    def __init__(self, ids, img_dir, transform=None):\n        self.ids = ids\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        img_name = self.ids.loc[idx, 'image_id']\n        img_path = os.path.join(self.img_dir, img_name)\n        \n        try:\n            image = Image.open(img_path).convert('RGB')\n            if self.transform:\n                image = self.transform(image)\n            return image, img_name\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n            # Return dummy image if loading fails\n            dummy_image = torch.zeros(3, image_size, image_size)\n            return dummy_image, img_name\n\nprint(\"✅ Test dataset class defined\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" Load Test Data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load test image IDs\ntest_ids_path = \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test_ids.csv\"\ntest_dir = \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test\"\n\ntest_ids = pd.read_csv(test_ids_path)\nprint(f\"✅ Loaded {len(test_ids)} test images\")\n\n# Create test dataset and dataloader\ntest_dataset = TestDataset(test_ids, test_dir, transform=val_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nprint(f\"✅ Test dataset created with {len(test_dataset)} images\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Make Predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_predictions(model, test_loader):\n    \"\"\"Make predictions on test data\"\"\"\n    model.eval()\n    predictions = []\n    \n    print(\"🔮 Making predictions...\")\n    \n    with torch.no_grad():\n        for batch_idx, (images, image_names) in enumerate(test_loader):\n            images = images.to(device)\n            outputs = model(images)\n            probs = torch.sigmoid(outputs)\n            preds = (probs > 0.5).int().cpu().numpy().flatten()\n            \n            for img_name, pred in zip(image_names, preds):\n                predictions.append((img_name, pred))\n            \n            if (batch_idx + 1) % 10 == 0:\n                print(f\"Processed {(batch_idx + 1) * 32} images\")\n    \n    print(f\"✅ Predictions completed for {len(predictions)} images\")\n    return predictions\n\n# Make predictions\npredictions = make_predictions(model, test_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Create Submission File","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_submission(predictions, output_path=\"submission.csv\"):\n    \"\"\"Create submission file\"\"\"\n    # Convert to DataFrame\n    submission = pd.DataFrame(predictions, columns=['image_id', 'label'])\n    \n    # Display statistics\n    print(\"📊 Submission Statistics:\")\n    print(f\"Total predictions: {len(submission)}\")\n    print(f\"Soil predictions (1): {sum(submission['label'])}\")\n    print(f\"Non-soil predictions (0): {len(submission) - sum(submission['label'])}\")\n    print(f\"Soil percentage: {(sum(submission['label']) / len(submission)) * 100:.2f}%\")\n    \n    # Save to CSV\n    submission.to_csv(output_path, index=False)\n    print(f\"✅ {output_path} saved!\")\n    \n    # Display sample\n    print(\"\\n📋 Sample predictions:\")\n    print(submission.head())\n    \n    return submission\n\n# Create submission\nsubmission_df = create_submission(predictions, \"final_submission.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}